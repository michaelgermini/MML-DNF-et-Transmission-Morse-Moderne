"""
Gestionnaire Unicode pour DNF-MML-Morse

G√®re la conversion des caract√®res Unicode en s√©quences Morse,
avec support pour les caract√®res accentu√©s, √©mojis, et autres scripts.
"""

import unicodedata
import re
from typing import Dict, Any, List, Optional, Tuple, Set
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


class UnicodeHandler:
    """
    Gestionnaire Unicode pour la transmission Morse

    Convertit les caract√®res Unicode en s√©quences Morse via :
    1. Normalisation Unicode (NFD/NFC)
    2. Translitt√©ration pour les scripts non-latins
    3. D√©composition des caract√®res combin√©s
    4. Fallback pour les caract√®res non support√©s
    """

    def __init__(self):
        """Initialisation du gestionnaire Unicode"""
        self._load_transliteration_tables()
        self._load_emoji_mappings()
        self._load_extended_latin_mappings()

        # Statistiques
        self.stats = {
            'characters_processed': 0,
            'unicode_characters': 0,
            'transliterations': 0,
            'fallbacks': 0,
        }

    def _load_transliteration_tables(self):
        """Charge les tables de translitt√©ration"""
        # Translitt√©ration cyrillique vers latin
        self.cyrillic_to_latin = {
            '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'E',
            '–ñ': 'ZH', '–ó': 'Z', '–ò': 'I', '–ô': 'J', '–ö': 'K', '–õ': 'L', '–ú': 'M',
            '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
            '–§': 'F', '–•': 'KH', '–¶': 'TS', '–ß': 'CH', '–®': 'SH', '–©': 'SHCH',
            '–™': '', '–´': 'Y', '–¨': '', '–≠': 'E', '–Æ': 'YU', '–Ø': 'YA',
            # Minuscules
            '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'e',
            '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'j', '–∫': 'k', '–ª': 'l', '–º': 'm',
            '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
            '—Ñ': 'f', '—Ö': 'kh', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'shch',
            '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        }

        # Translitt√©ration grecque
        self.greek_to_latin = {
            'Œë': 'A', 'Œí': 'B', 'Œì': 'G', 'Œî': 'D', 'Œï': 'E', 'Œñ': 'Z', 'Œó': 'H',
            'Œò': 'TH', 'Œô': 'I', 'Œö': 'K', 'Œõ': 'L', 'Œú': 'M', 'Œù': 'N', 'Œû': 'X',
            'Œü': 'O', 'Œ†': 'P', 'Œ°': 'R', 'Œ£': 'S', 'Œ§': 'T', 'Œ•': 'Y', 'Œ¶': 'F',
            'Œß': 'CH', 'Œ®': 'PS', 'Œ©': 'O',
            # Minuscules
            'Œ±': 'a', 'Œ≤': 'b', 'Œ≥': 'g', 'Œ¥': 'd', 'Œµ': 'e', 'Œ∂': 'z', 'Œ∑': 'h',
            'Œ∏': 'th', 'Œπ': 'i', 'Œ∫': 'k', 'Œª': 'l', 'Œº': 'm', 'ŒΩ': 'n', 'Œæ': 'x',
            'Œø': 'o', 'œÄ': 'p', 'œÅ': 'r', 'œÉ': 's', 'œÑ': 't', 'œÖ': 'y', 'œÜ': 'f',
            'œá': 'ch', 'œà': 'ps', 'œâ': 'o',
        }

        # Translitt√©ration h√©bra√Øque basique
        self.hebrew_to_latin = {
            '◊ê': "'", '◊ë': 'b', '◊í': 'g', '◊ì': 'd', '◊î': 'h', '◊ï': 'v', '◊ñ': 'z',
            '◊ó': 'kh', '◊ò': 't', '◊ô': 'y', '◊õ': 'k', '◊ú': 'l', '◊û': 'm', '◊†': 'n',
            '◊°': 's', '◊¢': "'", '◊§': 'p', '◊¶': 'ts', '◊ß': 'k', '◊®': 'r', '◊©': 'sh',
            '◊™': 't',
        }

        # Translitt√©ration arabe basique
        self.arabic_to_latin = {
            'ÿß': 'a', 'ÿ®': 'b', 'ÿ™': 't', 'ÿ´': 'th', 'ÿ¨': 'j', 'ÿ≠': 'h', 'ÿÆ': 'kh',
            'ÿØ': 'd', 'ÿ∞': 'dh', 'ÿ±': 'r', 'ÿ≤': 'z', 'ÿ≥': 's', 'ÿ¥': 'sh', 'ÿµ': 's',
            'ÿ∂': 'd', 'ÿ∑': 't', 'ÿ∏': 'z', 'ÿπ': "'", 'ÿ∫': 'gh', 'ŸÅ': 'f', 'ŸÇ': 'q',
            'ŸÉ': 'k', 'ŸÑ': 'l', 'ŸÖ': 'm', 'ŸÜ': 'n', 'Ÿá': 'h', 'Ÿà': 'w', 'Ÿä': 'y',
        }

    def _load_extended_latin_mappings(self):
        """Charge les mappings pour caract√®res latins √©tendus"""
        # Caract√®res accentu√©s courants
        self.extended_latin = {
            # Fran√ßais
            '√†': 'a', '√¢': 'a', '√§': 'a', '√©': 'e', '√®': 'e', '√™': 'e', '√´': 'e',
            '√Ø': 'i', '√Æ': 'i', '√¥': 'o', '√∂': 'o', '√π': 'u', '√ª': 'u', '√º': 'u',
            '√ø': 'y', '√ß': 'c',
            # Majuscules accentu√©es
            '√Ä': 'A', '√Ç': 'A', '√Ñ': 'A', '√â': 'E', '√à': 'E', '√ä': 'E', '√ã': 'E',
            '√è': 'I', '√é': 'I', '√î': 'O', '√ñ': 'O', '√ô': 'U', '√õ': 'U', '√ú': 'U',
            '≈∏': 'Y', '√á': 'C',
            # Espagnol
            '√°': 'a', '√≠': 'i', '√≥': 'o', '√∫': 'u', '√±': 'n',
            '√Å': 'A', '√ç': 'I', '√ì': 'O', '√ö': 'U', '√ë': 'N',
            # Portugais
            '√£': 'a', '√µ': 'o', '√¢': 'a', '√™': 'e', '√¥': 'o',
            '√É': 'A', '√ï': 'O', '√Ç': 'A', '√ä': 'E', '√î': 'O',
            # Allemand
            '√ü': 'ss',
            # Autres
            '√∏': 'o', '√ò': 'O', '√•': 'a', '√Ö': 'A',
        }

    def _load_emoji_mappings(self):
        """Charge les mappings pour √©mojis courants"""
        # √âmojis de communication couramment utilis√©s
        self.emoji_mappings = {
            '‚ù§Ô∏è': '<3', 'üëç': 'OK', 'üëé': 'KO', 'üòÇ': 'LOL', 'üòä': ':)', 'üò¢': ':(',
            'üòÆ': ':O', 'üòç': '<3', 'ü§î': '?!', 'üôÑ': ':/', 'üò¥': 'ZZZ', 'üíØ': '100',
            'üî•': 'HOT', 'üí™': 'STR', 'üéâ': 'YAY', 'üíî': 'X3', 'üòé': '8)', 'ü§ó': 'HUG',
            'üòá': 'HALO', 'üòà': 'DEVIL', 'üëª': 'GHOST', 'üí©': 'POO', 'üê±': 'CAT', 'üê∂': 'DOG',
            'üåü': 'STAR', '‚ö°': 'FLASH', '‚ùÑÔ∏è': 'ICE', 'üî•': 'FIRE', 'üíß': 'DROP', 'üåà': 'RAINBOW',
            'üåû': 'SUN', 'üåô': 'MOON', '‚≠ê': 'STAR', '‚ú®': 'SPARKLE', 'üîÆ': 'BALL',
            'üéµ': 'MUSIC', 'üé∂': 'NOTE', 'üé§': 'MIC', 'üéß': 'HEAD', 'üì±': 'PHONE', 'üíª': 'PC',
            'üöÄ': 'ROCKET', '‚úàÔ∏è': 'PLANE', 'üöó': 'CAR', 'üè†': 'HOME', 'üèÉ': 'RUN', '‚öΩ': 'BALL',
            'üçï': 'PIZZA', '‚òï': 'COFFEE', 'üç∫': 'BEER', 'üéÇ': 'CAKE', 'üéÅ': 'GIFT',
        }

        # Cat√©gories d'√©mojis pour fallback
        self.emoji_categories = {
            'smileys': ['üòÄ', 'üòÉ', 'üòÑ', 'üòÅ', 'üòÜ', 'üòÖ', 'üòÇ', 'ü§£', 'üòä', 'üòá'],
            'hearts': ['‚ù§Ô∏è', 'üíõ', 'üíö', 'üíô', 'üíú', 'üñ§', 'ü§ç', 'ü§é', 'üíî', 'üíï'],
            'gestures': ['üëç', 'üëé', 'üëå', '‚úåÔ∏è', 'ü§û', 'üëè', 'üôå', 'ü§ù', 'üôè', '‚úä'],
            'nature': ['üå±', 'üåø', 'üåæ', 'üåµ', 'üå≤', 'üå≥', 'üå¥', 'üå∏', 'üå∫', 'üåª'],
            'weather': ['‚òÄÔ∏è', 'üå§Ô∏è', '‚õÖ', '‚òÅÔ∏è', 'üåßÔ∏è', '‚õàÔ∏è', 'üå©Ô∏è', '‚ùÑÔ∏è', 'üå®Ô∏è', 'üå™Ô∏è'],
        }

    def normalize_unicode(self, text: str, mode: str = 'transliterate') -> str:
        """
        Normalise le texte Unicode pour la transmission Morse

        Args:
            text: Texte Unicode √† normaliser
            mode: Mode de normalisation ('transliterate', 'decompose', 'remove')

        Returns:
            Texte normalis√©
        """
        if not text:
            return ""

        original_length = len(text)
        processed_chars = 0
        unicode_chars = 0
        transliterations = 0
        fallbacks = 0

        result_parts = []

        for char in text:
            processed_chars += 1

            # Caract√®re ASCII standard - pas de traitement
            if ord(char) < 128:
                result_parts.append(char)
                continue

            unicode_chars += 1
            replacement = None

            # 1. Essai des mappings directs
            if char in self.emoji_mappings:
                replacement = self.emoji_mappings[char]
                transliterations += 1
            elif char in self.extended_latin:
                replacement = self.extended_latin[char]
                transliterations += 1
            elif char in self.cyrillic_to_latin:
                replacement = self.cyrillic_to_latin[char]
                transliterations += 1
            elif char in self.greek_to_latin:
                replacement = self.greek_to_latin[char]
                transliterations += 1
            elif char in self.hebrew_to_latin:
                replacement = self.hebrew_to_latin[char]
                transliterations += 1
            elif char in self.arabic_to_latin:
                replacement = self.arabic_to_latin[char]
                transliterations += 1

            # 2. Normalisation Unicode (d√©composition)
            if replacement is None:
                try:
                    # D√©composition canonique
                    decomposed = unicodedata.normalize('NFD', char)

                    # Garde seulement les caract√®res de base (pas les diacritiques)
                    base_chars = []
                    for c in decomposed:
                        if unicodedata.category(c) != 'Mn':  # Non-spacing mark
                            base_chars.append(c)

                    if base_chars and base_chars[0].isalpha():
                        replacement = ''.join(base_chars)
                        transliterations += 1
                except:
                    pass

            # 3. Fallback selon le mode
            if replacement is None:
                if mode == 'remove':
                    replacement = ''  # Supprimer
                elif mode == 'decompose':
                    try:
                        # Essai de d√©composition compl√®te
                        decomposed = unicodedata.normalize('NFD', char)
                        replacement = ''.join(c for c in decomposed if unicodedata.category(c) != 'Mn')
                        if not replacement:
                            replacement = '?'
                    except:
                        replacement = '?'
                else:  # transliterate
                    # Repr√©sentation num√©rique pour caract√®res inconnus
                    replacement = f"{{{ord(char):04X}}}"
                fallbacks += 1

            result_parts.append(replacement)

        result = ''.join(result_parts)

        # Mise √† jour des statistiques
        self.stats['characters_processed'] += processed_chars
        self.stats['unicode_characters'] += unicode_chars
        self.stats['transliterations'] += transliterations
        self.stats['fallbacks'] += fallbacks

        logger.debug(f"Normalis√© {unicode_chars} caract√®res Unicode sur {processed_chars} total")

        return result

    def get_unicode_info(self, text: str) -> Dict[str, Any]:
        """
        Analyse les caract√®res Unicode dans un texte

        Args:
            text: Texte √† analyser

        Returns:
            Informations sur les caract√®res Unicode
        """
        unicode_chars = []
        scripts = defaultdict(int)
        categories = defaultdict(int)

        for char in text:
            if ord(char) >= 128:  # Non-ASCII
                unicode_chars.append(char)

                # Script Unicode
                try:
                    script = unicodedata.script(char)
                    scripts[script] += 1
                except:
                    scripts['Unknown'] += 1

                # Cat√©gorie Unicode
                try:
                    category = unicodedata.category(char)
                    categories[category] += 1
                except:
                    categories['Unknown'] += 1

        return {
            'total_unicode_chars': len(unicode_chars),
            'unique_unicode_chars': len(set(unicode_chars)),
            'scripts': dict(scripts),
            'categories': dict(categories),
            'sample_chars': unicode_chars[:10],  # √âchantillon
        }

    def add_custom_mapping(self, char: str, replacement: str):
        """
        Ajoute un mapping personnalis√©

        Args:
            char: Caract√®re Unicode
            replacement: Cha√Æne de remplacement
        """
        if len(replacement) > 10:  # Limite de longueur
            raise ValueError("Le remplacement ne peut pas d√©passer 10 caract√®res")

        self.emoji_mappings[char] = replacement
        logger.info(f"Mapping personnalis√© ajout√©: {char} -> {replacement}")

    def get_supported_scripts(self) -> List[str]:
        """
        Retourne la liste des scripts support√©s

        Returns:
            Liste des scripts Unicode support√©s
        """
        return [
            'Latin', 'Cyrillic', 'Greek', 'Hebrew', 'Arabic',
            'Emoji', 'Extended_Latin'
        ]

    def get_stats(self) -> Dict[str, Any]:
        """
        Statistiques d'utilisation

        Returns:
            Statistiques d√©taill√©es
        """
        total_processed = self.stats['characters_processed']
        unicode_ratio = (self.stats['unicode_characters'] / max(total_processed, 1)) * 100

        return {
            'characters_processed': total_processed,
            'unicode_characters': self.stats['unicode_characters'],
            'unicode_ratio_percent': round(unicode_ratio, 2),
            'transliterations': self.stats['transliterations'],
            'fallbacks': self.stats['fallbacks'],
            'supported_scripts': self.get_supported_scripts(),
            'custom_mappings_count': len([k for k in self.emoji_mappings.keys() if k not in self._load_emoji_mappings.__defaults__[0]]),
        }


# Fonctions utilitaires
def normalize_unicode_text(text: str, mode: str = 'transliterate') -> str:
    """
    Fonction utilitaire pour normalisation Unicode

    Args:
        text: Texte √† normaliser
        mode: Mode de normalisation

    Returns:
        Texte normalis√©
    """
    handler = UnicodeHandler()
    return handler.normalize_unicode(text, mode)


def get_unicode_info(text: str) -> Dict[str, Any]:
    """
    Fonction utilitaire pour analyse Unicode

    Args:
        text: Texte √† analyser

    Returns:
        Informations Unicode
    """
    handler = UnicodeHandler()
    return handler.get_unicode_info(text)
